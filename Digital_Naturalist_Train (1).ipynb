{"cells": [{"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# -*- coding: utf-8 -*-\n", "\"\"\"\n", "Created on Thu Oct 22 23:48:24 2020"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["@author: Madhav Rathi\n", "\"\"\"\n", "#Libraries for Locating and loading data\n", "import pathlib\n", "from pathlib import Path\n", "import os, gc, glob, random\n", "from PIL import Image"]}, {"cell_type": "markdown", "metadata": {}, "source": ["or matrix calculations and data Managememnt"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import pandas as pd\n", "import numpy as np"]}, {"cell_type": "markdown", "metadata": {}, "source": ["mporting libraries required for the model"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import tensorflow as tf\n", "import keras \n", "import keras.backend as K"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from keras.optimizers import SGD, Adam, Adagrad, RMSprop\n", "from keras.applications import *\n", "from keras.preprocessing import *\n", "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n", "from keras.callbacks import EarlyStopping, ModelCheckpoint\n", "from keras.models import Sequential\n", "from keras.layers import Dense, Conv2D, MaxPool2D, Flatten, Activation, BatchNormalization,Dropout\n", "from keras.models import Model\n", "from keras.utils.np_utils import to_categorical\n", "from sklearn.model_selection import train_test_split"]}, {"cell_type": "markdown", "metadata": {}, "source": ["or plotting charts used for data visualizations"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import matplotlib.pyplot as plt"]}, {"cell_type": "markdown", "metadata": {}, "source": ["sed to load model in testing phase"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from keras.models import load_model\n", "from keras.models import model_from_json"]}, {"cell_type": "markdown", "metadata": {}, "source": ["etting the names for all the folders containing data"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import os\n", "from os import listdir\n", "dirName = 'D:\\SmartBridge\\VEC\\Digital-Naturalist-main\\Digital Naturalist Dataset'\n", "folders = listdir(dirName)\n", "        \n", "def getListOfFiles(dirName):\n", "# create a list of sub directories and files(if any)\n", "# names in the given directory \n", "    listOfFile = os.listdir(dirName)\n", "    allFiles = list()\n", "    for fol_name in listOfFile:\n", "        fullPath = os.path.join(dirName, fol_name)\n", "        allFiles.append(fullPath)\n", "              \n", "    return allFiles"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["Folders = getListOfFiles(dirName)\n", "len(Folders)\n", "subfolders = []\n", "for num in range(len(Folders)):\n", "    sub_fols = getListOfFiles(Folders[num])\n", "    subfolders+=sub_fols\n", "#Now, the subfolders contains the address to all our data folders for each class\n", "subfolders"]}, {"cell_type": "markdown", "metadata": {}, "source": ["\\\\\\\\\\\\\\/////////\\\\\\\\\\\\\\\\////////\\\\\\\\\\\\\\\\\\////////<br>\n", "\\\\\\\\\\\\\\/////////\\\\\\\\\\\\\\\\////////\\\\\\\\\\\\\\\\\\////////<br>\n", "oading the data and pre processing it to make it in trainable format<br>\n", "\\\\\\\\\\\\\\/////////\\\\\\\\\\\\\\\\////////\\\\\\\\\\\\\\\\\\////////<br>\n", "\\\\\\\\\\\\\\/////////\\\\\\\\\\\\\\\\////////\\\\\\\\\\\\\\\\\\////////"]}, {"cell_type": "markdown", "metadata": {}, "source": [" data will includes the data generated for each image<br>\n", " data will include a id no:, for every different boat type in out boats folder<br>\n", " different number is being assigned. That will be tha label we're classifying."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["X_data = []\n", "Y_data = []"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["id_no=0\n", "found = []\n", "#itering in all folders under Boats folder\n", "for paths in subfolders:\n", "    #setting folder path for each boat type\n", "    files = glob.glob (paths + \"/*.jpg\")\n", "    found.append((paths.split('\\\\')[-2],paths.split('\\\\')[-1]))\n", "    \n", "    #itering all files under the folder one by one\n", "    for myFile in files:\n", "        img = Image.open(myFile)\n", "        #img.thumbnail((width, height), Image.ANTIALIAS) # resizes image in-place keeps ratio\n", "        img = img.resize((224,224), Image.ANTIALIAS) # resizes image without ratio\n", "        #convert the images to numpy arrays\n", "        img = np.array(img)\n", "        if img.shape == ( 224, 224, 3):\n", "            # Add the numpy image to matrix with all data\n", "            X_data.append (img)\n", "            Y_data.append (id_no)\n", "    id_no+=1"]}, {"cell_type": "markdown", "metadata": {}, "source": ["o see our data"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print(X_data)\n", "print(Y_data)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["Y_data"]}, {"cell_type": "markdown", "metadata": {}, "source": ["onverting lists to np arrays again"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["X = np.array(X_data)\n", "Y = np.array(Y_data)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Print shapes to see if they are correct"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print(\"x-shape\",X.shape,\"y shape\", Y.shape)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["X = X.astype('float32')/255.0\n", "y_cat = to_categorical(Y_data, len(subfolders))"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print(\"X shape\",X,\"y_cat shape\", y_cat)\n", "print(\"X shape\",X.shape,\"y_cat shape\", y_cat.shape)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["\\\\\\\\\\\\\\/////////\\\\\\\\\\\\\\\\////////\\\\\\\\\\\\\\\\\\////////<br>\n", "\\\\\\\\\\\\\\/////////\\\\\\\\\\\\\\\\////////\\\\\\\\\\\\\\\\\\////////<br>\n", "plitting the data to Test and Train<br>\n", "\\\\\\\\\\\\\\/////////\\\\\\\\\\\\\\\\////////\\\\\\\\\\\\\\\\\\////////<br>\n", "\\\\\\\\\\\\\\/////////\\\\\\\\\\\\\\\\////////\\\\\\\\\\\\\\\\\\////////"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["X_train, X_test, y_train, y_test = train_test_split(X, y_cat, test_size=0.2)\n", "print(\"The model has \" + str(len(X_train)) + \" inputs\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["\\\\\\\\\\\\\\/////////\\\\\\\\\\\\\\\\////////\\\\\\\\\\\\\\\\\\////////<br>\n", "\\\\\\\\\\\\\\/////////\\\\\\\\\\\\\\\\////////\\\\\\\\\\\\\\\\\\////////<br>\n", " O D E L    B U I L D I N G<br>\n", "\\\\\\\\\\\\\\/////////\\\\\\\\\\\\\\\\////////\\\\\\\\\\\\\\\\\\////////<br>\n", "\\\\\\\\\\\\\\/////////\\\\\\\\\\\\\\\\////////\\\\\\\\\\\\\\\\\\////////"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["early_stop_loss = EarlyStopping(monitor='loss', patience=3, verbose=1)\n", "early_stop_val_acc = EarlyStopping(monitor='val_accuracy', patience=3, verbose=1)\n", "model_callbacks=[early_stop_loss, early_stop_val_acc]"]}, {"cell_type": "markdown", "metadata": {}, "source": ["efining our model, All the layers and configurations"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def load_CNN(output_size):\n", "  K.clear_session()\n", "  model = Sequential()\n", "  model.add(Dropout(0.4,input_shape=(224, 224, 3)))\n", "  \n", "  model.add(Conv2D(256, (5, 5),input_shape=(224, 224, 3),activation='relu'))\n", "  model.add(MaxPool2D(pool_size=(2, 2)))\n", "  #model.add(BatchNormalization())"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["  model.add(Conv2D(128, (3, 3), activation='relu'))\n", "  model.add(MaxPool2D(pool_size=(2, 2)))\n", "  #model.add(BatchNormalization())"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["  model.add(Conv2D(64, (3, 3), activation='relu'))\n", "  model.add(MaxPool2D(pool_size=(2, 2)))\n", "  #model.add(BatchNormalization())"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["  model.add(Flatten())\n", "  model.add(Dense(512, activation='relu'))\n", "  model.add(Dropout(0.3))\n", "  model.add(Dense(256, activation='relu'))\n", "  model.add(Dropout(0.3))\n", "  model.add(Dense(128, activation='relu'))\n", "  model.add(Dropout(0.3))"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["  model.add(Dense(output_size, activation='softmax'))\n", "  \n", "  return model"]}, {"cell_type": "markdown", "metadata": {}, "source": ["uilding a model based on the above defined function"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["model = load_CNN(6) #Number of Columns / Outputs\n", "model.compile(loss='categorical_crossentropy',optimizer=Adam(lr=0.001),metrics=['accuracy'])\n", "model.summary() #to print model summary\n", "weights = model.get_weights() #to get the weights from our model"]}, {"cell_type": "markdown", "metadata": {}, "source": ["\\\\\\\\\\\\\\/////////\\\\\\\\\\\\\\\\////////\\\\\\\\\\\\\\\\\\////////<br>\n", "\\\\\\\\\\\\\\/////////\\\\\\\\\\\\\\\\////////\\\\\\\\\\\\\\\\\\////////<br>\n", "itting the model on different batch sizes to see which ones turns out to be the best<br>\n", "\\\\\\\\\\\\\\/////////\\\\\\\\\\\\\\\\////////\\\\\\\\\\\\\\\\\\////////<br>\n", "\\\\\\\\\\\\\\/////////\\\\\\\\\\\\\\\\////////\\\\\\\\\\\\\\\\\\////////"]}, {"cell_type": "markdown", "metadata": {}, "source": ["ome arrays to store the result of each model (model trained on each bath size)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["histories_acc = []\n", "histories_val_acc = []\n", "histories_loss = []\n", "histories_val_loss = []"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["model.set_weights(weights)\n", "h=model.fit(X_train,y_train,\n", "              batch_size=16,\n", "              epochs=7,\n", "              verbose=1,\n", "              callbacks=[early_stop_loss],\n", "              shuffle=True,\n", "              validation_data=(X_test, y_test))"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["model.summary() #to print model summary"]}, {"cell_type": "markdown", "metadata": {}, "source": ["rinting the keys we have for the stores values"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print(h.history.keys())\n", "#appendind the data for each epoch in a arr, and for each batch size\n", "histories_acc.append(h.history['acc'])\n", "histories_val_acc.append(h.history['val_acc'])\n", "histories_loss.append(h.history['loss'])\n", "histories_val_loss.append(h.history['val_loss'])"]}, {"cell_type": "markdown", "metadata": {}, "source": ["onverting into numpy arrays"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["histories_acc = np.array(histories_acc)\n", "histories_val_acc = np.array(histories_val_acc)\n", "histories_loss = np.array(histories_loss)\n", "histories_val_loss = np.array(histories_val_loss)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["ere we have 3 columns and 6 rows each,ever row represetns differnt bath size,<br>\n", "very column represent different epoch scores."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print('histories_acc',histories_acc,\n", "      'histories_loss', histories_loss,\n", "      'histories_val_acc', histories_val_acc,\n", "      'histories_val_loss', histories_val_loss)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["oading Test Data "]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["image_number = random.randint(0,len(X_test))\n", "print(image_number)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["lotting the test image"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["plt.figure(figsize=(8, 8))\n", "plt.imshow(X_test[image_number])"]}, {"cell_type": "markdown", "metadata": {}, "source": ["\\\\\\\\\\\\\\/////////\\\\\\\\\\\\\\\\////////\\\\\\\\\\\\\\\\\\////////<br>\n", "\\\\\\\\\\\\\\/////////\\\\\\\\\\\\\\\\////////\\\\\\\\\\\\\\\\\\////////<br>\n", "redicting the image's classes<br>\n", "ndividual scores for each class as well as class with the highest score is printed<br>\n", "\\\\\\\\\\\\\\/////////\\\\\\\\\\\\\\\\////////\\\\\\\\\\\\\\\\\\////////<br>\n", "\\\\\\\\\\\\\\/////////\\\\\\\\\\\\\\\\////////\\\\\\\\\\\\\\\\\\////////"]}, {"cell_type": "markdown", "metadata": {}, "source": ["aking predictions ,storing result as array of probabilities of each class predicted"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["predictions = model.predict_proba([X_test[image_number].reshape(1, 224,224,3)])"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["for idx, result, x in zip(range(0,6), found, predictions[0]):\n", "   print(\"Label: {}, Type : {}, Species : {} , Score : {}%\".format(idx, result[0],result[1], round(x*100,3)))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["redicting the class with max probability"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["ClassIndex=model.predict_classes([X_test[image_number].reshape(1, 224,224,3)])"]}, {"cell_type": "markdown", "metadata": {}, "source": ["etting the index of the class which we can pass <br>\n", "o the boat_types list to get the boat type name"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["ClassIndex"]}, {"cell_type": "markdown", "metadata": {}, "source": ["rinting the final output"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print(found[ClassIndex[0]])"]}, {"cell_type": "markdown", "metadata": {}, "source": ["\\\\\\\\\\\\\\/////////\\\\\\\\\\\\\\\\////////\\\\\\\\\\\\\\\\\\////////<br>\n", "\\\\\\\\\\\\\\/////////\\\\\\\\\\\\\\\\////////\\\\\\\\\\\\\\\\\\////////<br>\n", "avig necessary model files<br>\n", "\\\\\\\\\\\\\\/////////\\\\\\\\\\\\\\\\////////\\\\\\\\\\\\\\\\\\////////<br>\n", "\\\\\\\\\\\\\\/////////\\\\\\\\\\\\\\\\////////\\\\\\\\\\\\\\\\\\////////"]}, {"cell_type": "markdown", "metadata": {}, "source": ["serialize model to JSON"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["model_json = model.to_json() #indent=2\n", "with open(\"final_model.json\", \"w\") as json_file:\n", "    json_file.write(model_json)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["serialize weights to H5"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["model.save_weights(\"final_model.h5\")\n", "print(\"Saved model to disk\")"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.4"}}, "nbformat": 4, "nbformat_minor": 2}